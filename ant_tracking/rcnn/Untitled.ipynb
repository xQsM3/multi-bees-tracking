{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import transforms\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "\n",
    "import detectron2.data.transforms as T\n",
    "\n",
    "\n",
    "from load_rcnn_model import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (2, 1024) in the checkpoint but (81, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (2,) in the checkpoint but (81,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (4, 1024) in the checkpoint but (320, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (4,) in the checkpoint but (320,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (2, 1024) in the checkpoint but (81, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (2,) in the checkpoint but (81,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (4, 1024) in the checkpoint but (320, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (4,) in the checkpoint but (320,) in the model! You might want to double check if this is expected.\n"
     ]
    }
   ],
   "source": [
    "model,predictor = load_model(conf_thresh=0.1)\n",
    "image = cv.imread(\"/media/linx123-rtx/Elements/Render/20190823/V23 back to hive_CR3000x2 1838-ST-159_1/V23 back to hive_CR3000x2 1838-ST-159_00000180.jpg\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "outputs = predictor(image)\n",
    "predictions = outputs[\"instances\"].to(\"cpu\")\n",
    "boxes_pred = predictions.pred_boxes if predictions.has(\"pred_boxes\") else None\n",
    "boxes_pred = boxes_pred.tensor.numpy()\n",
    "scores_pred = predictions.scores if predictions.has(\"scores\") else None\n",
    "scores_pred = scores_pred.numpy()\n",
    "classes_pred = predictions.pred_classes if predictions.has(\"pred_classes\") else None\n",
    "classes_pred = classes_pred.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'instances': Instances(num_instances=1, image_height=1710, image_width=1696, fields=[pred_boxes: Boxes(tensor([[ 915.3279, 1348.9526, 1682.6760, 1705.4668]], device='cuda:0')), scores: tensor([0.1037], device='cuda:0'), pred_classes: tensor([79], device='cuda:0')])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, -1, 581, 1111, 49, 49, 1], [0, -1, 666, 1596, 53, 52, 1]]\n"
     ]
    }
   ],
   "source": [
    "for box_pred,score_pred,classes_pred in zip(boxes_pred,scores_pred,classes_pred):\n",
    "    det_list.append([0,-1,round(box_pred[0]),round(box_pred[1]),\n",
    "                     round(box_pred[2]-box_pred[0]),round(box_pred[3]-box_pred[1]),1])\n",
    "print(det_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train(False)\n",
    "var_image = torch.tensor(image).permute(2,0,1)\n",
    "inputs = {\"image\":var_image}\n",
    "outputs = model([inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linx123-rtx/anaconda3/envs/multi-ants-tracking/lib/python3.8/site-packages/detectron2/modeling/roi_heads/fast_rcnn.py:124: UserWarning: This overload of nonzero is deprecated:\n",
      "\tnonzero()\n",
      "Consider using one of the following signatures instead:\n",
      "\tnonzero(*, bool as_tuple) (Triggered internally at  /opt/conda/conda-bld/pytorch_1607370172916/work/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
      "  filter_inds = filter_mask.nonzero()\n"
     ]
    }
   ],
   "source": [
    "model.train(False) # inference mode\n",
    "import numpy as np\n",
    "\n",
    "img = cv.imread(\"/media/linx123-rtx/Elements/Render/20190823/V23 back to hive_CR3000x2 1838-ST-159_1/V23 back to hive_CR3000x2 1838-ST-159_00000180.jpg\")\n",
    "img = np.transpose(img,(2,0,1))\n",
    "img_tensor = torch.from_numpy(img)\n",
    "inputs = [{\"image\":img_tensor}] # inputs is ready\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iou_matrix = [2]\n",
    "iou_matrix == []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow(\"window\",np.array(var_image.permute(1,2,0)) )\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = [1,2]\n",
    "l[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
